{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Multivariate DTW Create\n",
    "\n",
    "2- Multivariate Dataset Prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Multivariate DTW Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Handwriting1.npy', 'Handwriting2.npy', 'Handwriting3.npy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First DTW mix\n",
    "data_path = os.getcwd()\n",
    "dtws_path = os.path.join(data_path, \"Handwriting_dtws\")\n",
    "os.listdir(dtws_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 48.123909  , 41.70343732, ..., 39.0921056 ,\n",
       "        38.45385485, 42.01710345],\n",
       "       [48.123909  ,  0.        , 36.68171117, ..., 33.15126484,\n",
       "        34.22257459, 37.93936611],\n",
       "       [41.70343732, 36.68171117,  0.        , ..., 21.77903903,\n",
       "        36.08866906, 42.42925969],\n",
       "       ...,\n",
       "       [39.0921056 , 33.15126484, 21.77903903, ...,  0.        ,\n",
       "        35.52048975, 36.16811319],\n",
       "       [38.45385485, 34.22257459, 36.08866906, ..., 35.52048975,\n",
       "         0.        , 41.90419983],\n",
       "       [42.01710345, 37.93936611, 42.42925969, ..., 36.16811319,\n",
       "        41.90419983,  0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npy_len = len(np.load(os.path.join(dtws_path, (os.listdir(dtws_path)[0]))))\n",
    "\n",
    "dtw = np.zeros((npy_len, npy_len))\n",
    "for file in os.listdir(dtws_path):\n",
    "    dtw+=np.load(os.path.join(dtws_path, file))\n",
    "dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"outputs/Handwriting_multi\", dtw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Multivariate Dataset Prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset_name = \"Handwriting\"\n",
    "\n",
    "dataset_files = [f for f in os.listdir(data_path) if f.startswith(base_dataset_name) and (f.endswith('_TRAIN.csv') or f.endswith('_TEST.csv'))]\n",
    "dataset_names = sorted(set(f.split('_')[0] for f in dataset_files))\n",
    "\n",
    "dataset_list = []\n",
    "\n",
    "for dataset in dataset_names:\n",
    "    # Read training and test data\n",
    "    train_df = pd.read_csv(os.path.join(data_path, f\"{dataset}_TRAIN.csv\"), header=None).iloc[:, 1:]\n",
    "    test_df = pd.read_csv(os.path.join(data_path, f\"{dataset}_TEST.csv\"), header=None).iloc[:, 1:]\n",
    "    \n",
    "    # Concatenate train and test data\n",
    "    full_df = pd.concat([train_df, test_df])\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    data_array = full_df.values\n",
    "    \n",
    "    # Reshape the data array\n",
    "    data_array = data_array.reshape((data_array.shape[0], 1, data_array.shape[1]))\n",
    "    \n",
    "    # Append to the dataset list\n",
    "    dataset_list.append(data_array)\n",
    "\n",
    "# Concatenate all datasets along the last axis\n",
    "final_dataset = np.concatenate(dataset_list, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      21\n",
       "1      22\n",
       "2      22\n",
       "3      17\n",
       "4      17\n",
       "       ..\n",
       "845    16\n",
       "846    26\n",
       "847    14\n",
       "848     1\n",
       "849    22\n",
       "Name: 0, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv(os.path.join(data_path, \"Handwriting1_TRAIN.csv\"), header=None).iloc[:,0]\n",
    "test_labels = pd.read_csv(os.path.join(data_path, \"Handwriting1_TEST.csv\"), header=None).iloc[:,0]\n",
    "dataset_labels = pd.concat([train_labels, test_labels])\n",
    "dataset_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"outputs/Handwriting_label.txt\", dataset_labels.values, fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"outputs/Handwriting.npy\", final_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_try",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
