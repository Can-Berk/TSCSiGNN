{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwG2bcrlV548",
        "outputId": "cdf9f54c-8224-42c3-898e-e2666e65dfc6"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
        "from sklearn.preprocessing import normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y7-1N3QyV7Q2"
      },
      "outputs": [],
      "source": [
        "def read_multivariate_dataset(root_dir, dataset_name):\n",
        "    \"\"\" Read multivariate dataset\n",
        "    \"\"\"\n",
        "    X = np.load(os.path.join(root_dir, dataset_name+\".npy\"), allow_pickle=True)\n",
        "    y = np.loadtxt(os.path.join(root_dir, dataset_name+'_label.txt'))\n",
        "    y = y.astype(np.int64)\n",
        "\n",
        "    dc = {'CharacterTrajectories_train_size': 1422,\n",
        "          'CharacterTrajectories_eq_train_size': 1422,\n",
        "               'PhonemeSpectra_train_size': 3315,\n",
        "               'Handwriting_train_size': 150,\n",
        "               'RacketSports_train_size': 151}\n",
        "\n",
        "\n",
        "\n",
        "    dim = X[0].shape[0]\n",
        "    max_length = 0\n",
        "    for _X in X:\n",
        "        if _X.shape[1] > max_length:\n",
        "            max_length = _X.shape[1]\n",
        "\n",
        "    X_list = []\n",
        "    for i in range(len(X)):\n",
        "        _X = np.zeros((dim, max_length))\n",
        "        _X[:, :X[i].shape[1]] = X[i]\n",
        "        X_list.append(_X)\n",
        "    X = np.array(X_list, dtype=np.float32)\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    le.fit(y)\n",
        "    y = le.transform(y)\n",
        "\n",
        "    idx = np.array([i for i in range(len(X))])\n",
        "\n",
        "    train_size=dc[str(dataset_name)+'_train_size']\n",
        "\n",
        "    # np.random.shuffle(idx)\n",
        "    train_idx, test_idx = idx[:train_size], idx[train_size:]\n",
        "            \n",
        "    print(len(train_idx))\n",
        "    print(len(test_idx))\n",
        "\n",
        "    x_train = X[train_idx]\n",
        "    y_train = y[train_idx]\n",
        "\n",
        "    x_test = X[test_idx]\n",
        "    y_test = y[test_idx]\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u415s-2RV9M4",
        "outputId": "92d957dc-1908-4a60-fcd9-bcb5b5a7c1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150\n",
            "850\n"
          ]
        }
      ],
      "source": [
        "root_url = os.getcwd()\n",
        "folder = \"/datasets/multivariate/\"\n",
        "dataset = \"Handwriting\"   # Handwriting, CharacterTrajectories, PhonemeSpectra\n",
        "x_train, y_train, x_test, y_test = read_multivariate_dataset(root_url+folder, dataset)\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "x_train = x_train.transpose(0,2,1)\n",
        "x_test = x_test.transpose(0,2,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fQE-4xjHWA2O"
      },
      "outputs": [],
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Attention and Normalization\n",
        "    x, att_scores = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(inputs, inputs, return_attention_scores=True)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    return x + res, att_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aA5IeUUUWEkA"
      },
      "outputs": [],
      "source": [
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x, att_scores = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
        "    return keras.Model(inputs, outputs), att_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwGf3nOVWGo4",
        "outputId": "e0e0b8af-519b-4813-ca2e-1caa120d0028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 152, 3)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention (MultiHead ((None, 152, 3), (No 15363       input_1[0][0]                    \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 152, 3)       0           multi_head_attention[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization (LayerNorma (None, 152, 3)       6           dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 152, 3)       0           layer_normalization[0][0]        \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 152, 4)       16          tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 152, 4)       0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 152, 3)       15          dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_1 (LayerNor (None, 152, 3)       6           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 152, 3)       0           layer_normalization_1[0][0]      \n",
            "                                                                 tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_1 (MultiHe ((None, 152, 3), (No 15363       tf.__operators__.add_1[0][0]     \n",
            "                                                                 tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 152, 3)       0           multi_head_attention_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_2 (LayerNor (None, 152, 3)       6           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 152, 3)       0           layer_normalization_2[0][0]      \n",
            "                                                                 tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 152, 4)       16          tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 152, 4)       0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 152, 3)       15          dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_3 (LayerNor (None, 152, 3)       6           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 152, 3)       0           layer_normalization_3[0][0]      \n",
            "                                                                 tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_2 (MultiHe ((None, 152, 3), (No 15363       tf.__operators__.add_3[0][0]     \n",
            "                                                                 tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 152, 3)       0           multi_head_attention_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_4 (LayerNor (None, 152, 3)       6           dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_4 (TFOpLam (None, 152, 3)       0           layer_normalization_4[0][0]      \n",
            "                                                                 tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 152, 4)       16          tf.__operators__.add_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 152, 4)       0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 152, 3)       15          dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_5 (LayerNor (None, 152, 3)       6           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_5 (TFOpLam (None, 152, 3)       0           layer_normalization_5[0][0]      \n",
            "                                                                 tf.__operators__.add_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_3 (MultiHe ((None, 152, 3), (No 15363       tf.__operators__.add_5[0][0]     \n",
            "                                                                 tf.__operators__.add_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 152, 3)       0           multi_head_attention_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_6 (LayerNor (None, 152, 3)       6           dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_6 (TFOpLam (None, 152, 3)       0           layer_normalization_6[0][0]      \n",
            "                                                                 tf.__operators__.add_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 152, 4)       16          tf.__operators__.add_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 152, 4)       0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 152, 3)       15          dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_7 (LayerNor (None, 152, 3)       6           conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_7 (TFOpLam (None, 152, 3)       0           layer_normalization_7[0][0]      \n",
            "                                                                 tf.__operators__.add_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 152)          0           tf.__operators__.add_7[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          19584       global_average_pooling1d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 128)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 26)           3354        dropout_8[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 84,562\n",
            "Trainable params: 84,562\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            "1/1 [==============================] - 5s 5s/step - loss: 3.4503 - sparse_categorical_accuracy: 0.0583 - val_loss: 3.4018 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 3.4796 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.3983 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 3.4698 - sparse_categorical_accuracy: 0.0333 - val_loss: 3.3944 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 3.3372 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.3905 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 3.3062 - sparse_categorical_accuracy: 0.0917 - val_loss: 3.3870 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 3.2866 - sparse_categorical_accuracy: 0.0917 - val_loss: 3.3832 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 3.3223 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.3791 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 3.1839 - sparse_categorical_accuracy: 0.0667 - val_loss: 3.3753 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 3.2421 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.3712 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 3.2021 - sparse_categorical_accuracy: 0.0417 - val_loss: 3.3673 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 3.2126 - sparse_categorical_accuracy: 0.0750 - val_loss: 3.3633 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 3.1832 - sparse_categorical_accuracy: 0.0500 - val_loss: 3.3589 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 3.1949 - sparse_categorical_accuracy: 0.0833 - val_loss: 3.3555 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 3.1520 - sparse_categorical_accuracy: 0.1083 - val_loss: 3.3524 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 3.0830 - sparse_categorical_accuracy: 0.1500 - val_loss: 3.3494 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 3.0982 - sparse_categorical_accuracy: 0.0917 - val_loss: 3.3464 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 3.0473 - sparse_categorical_accuracy: 0.1333 - val_loss: 3.3434 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 3.0095 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.3406 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 3.0282 - sparse_categorical_accuracy: 0.1417 - val_loss: 3.3376 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.9784 - sparse_categorical_accuracy: 0.1333 - val_loss: 3.3351 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.9142 - sparse_categorical_accuracy: 0.2000 - val_loss: 3.3332 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.9177 - sparse_categorical_accuracy: 0.1833 - val_loss: 3.3314 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.8980 - sparse_categorical_accuracy: 0.1250 - val_loss: 3.3296 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.8866 - sparse_categorical_accuracy: 0.2000 - val_loss: 3.3280 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.9143 - sparse_categorical_accuracy: 0.1500 - val_loss: 3.3264 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.7917 - sparse_categorical_accuracy: 0.1667 - val_loss: 3.3248 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.7665 - sparse_categorical_accuracy: 0.2583 - val_loss: 3.3234 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 2.8006 - sparse_categorical_accuracy: 0.2083 - val_loss: 3.3222 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.7730 - sparse_categorical_accuracy: 0.2167 - val_loss: 3.3211 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.7933 - sparse_categorical_accuracy: 0.1750 - val_loss: 3.3194 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.7446 - sparse_categorical_accuracy: 0.2250 - val_loss: 3.3181 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.7054 - sparse_categorical_accuracy: 0.2250 - val_loss: 3.3165 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.7093 - sparse_categorical_accuracy: 0.2167 - val_loss: 3.3157 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.7050 - sparse_categorical_accuracy: 0.2333 - val_loss: 3.3151 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.7243 - sparse_categorical_accuracy: 0.2333 - val_loss: 3.3128 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.6684 - sparse_categorical_accuracy: 0.2417 - val_loss: 3.3117 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.6088 - sparse_categorical_accuracy: 0.3167 - val_loss: 3.3079 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.6146 - sparse_categorical_accuracy: 0.3000 - val_loss: 3.3063 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.5606 - sparse_categorical_accuracy: 0.2833 - val_loss: 3.3050 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.6248 - sparse_categorical_accuracy: 0.2667 - val_loss: 3.3043 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.4948 - sparse_categorical_accuracy: 0.3417 - val_loss: 3.3037 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.5434 - sparse_categorical_accuracy: 0.2583 - val_loss: 3.3045 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.5091 - sparse_categorical_accuracy: 0.3250 - val_loss: 3.3048 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.5084 - sparse_categorical_accuracy: 0.3083 - val_loss: 3.3063 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.5378 - sparse_categorical_accuracy: 0.3500 - val_loss: 3.3058 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.5204 - sparse_categorical_accuracy: 0.3250 - val_loss: 3.3060 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.5116 - sparse_categorical_accuracy: 0.2917 - val_loss: 3.3055 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 2.3559 - sparse_categorical_accuracy: 0.4083 - val_loss: 3.3046 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.4034 - sparse_categorical_accuracy: 0.4000 - val_loss: 3.3042 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.3202 - sparse_categorical_accuracy: 0.4083 - val_loss: 3.3036 - val_sparse_categorical_accuracy: 0.0333\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.3664 - sparse_categorical_accuracy: 0.4083 - val_loss: 3.3032 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 2.3620 - sparse_categorical_accuracy: 0.4167 - val_loss: 3.3029 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.4136 - sparse_categorical_accuracy: 0.4250 - val_loss: 3.3024 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.3542 - sparse_categorical_accuracy: 0.4250 - val_loss: 3.3020 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 2.2401 - sparse_categorical_accuracy: 0.4667 - val_loss: 3.3025 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2691 - sparse_categorical_accuracy: 0.4333 - val_loss: 3.3042 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2936 - sparse_categorical_accuracy: 0.4250 - val_loss: 3.3051 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 2.2653 - sparse_categorical_accuracy: 0.4417 - val_loss: 3.3056 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.2169 - sparse_categorical_accuracy: 0.4833 - val_loss: 3.3050 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.2036 - sparse_categorical_accuracy: 0.4583 - val_loss: 3.3054 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 2.1844 - sparse_categorical_accuracy: 0.5083 - val_loss: 3.3060 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.1617 - sparse_categorical_accuracy: 0.4833 - val_loss: 3.3066 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.1683 - sparse_categorical_accuracy: 0.5167 - val_loss: 3.3077 - val_sparse_categorical_accuracy: 0.0667\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 2.1065 - sparse_categorical_accuracy: 0.5167 - val_loss: 3.3084 - val_sparse_categorical_accuracy: 0.0667\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1a264a98a60>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_shape = x_train.shape[1:]   # time steps\n",
        "\n",
        "model, att_scores = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[128],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=5e-4),   # 1e-4 and 1e-3\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=200,\n",
        "    batch_size=128,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "# model.evaluate(x_test, y_test, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH5NLVG8Vt3c"
      },
      "source": [
        "# Full Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<KerasTensor: shape=(None, 152, 3) dtype=float32 (created by layer 'multi_head_attention')>,\n",
              " <KerasTensor: shape=(None, 4, 152, 152) dtype=float32 (created by layer 'multi_head_attention')>)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_layer('multi_head_attention').output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = np.concatenate((x_train, x_test))\n",
        "y = np.concatenate((y_train, y_test))\n",
        "\n",
        "mha = keras.models.Model(inputs=model.input, outputs=[model.get_layer('multi_head_attention').output, att_scores]) # multi_head_attention_21 and att_score as outputs\n",
        "out, att_scores_mha3 = mha.predict(X)    # returns 'out': specified multi-head attention (mha) layer attention outputs and attention scores, 'att_scores_mha3': last mha layer scores.\n",
        "attention_outputs, attention_scores = out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Attention Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attention_scores dims: (1000, 4, 152, 152)\n",
            "attention_outputs dims: (1000, 152, 3)\n"
          ]
        }
      ],
      "source": [
        "print('attention_scores dims:', attention_scores.shape)\n",
        "print('attention_outputs dims:', attention_outputs.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity Matrix (Cosine Similarity):\n",
            " [[1.0000092  0.9999824  0.9999682  ... 0.99997365 0.9999483  0.9999755 ]\n",
            " [0.9999824  1.0000196  0.99997514 ... 0.9999855  0.99996156 0.99998754]\n",
            " [0.9999682  0.99997514 0.9999805  ... 0.9999697  0.99994564 0.9999677 ]\n",
            " ...\n",
            " [0.99997365 0.9999855  0.9999697  ... 1.0000155  0.99995327 0.999978  ]\n",
            " [0.9999483  0.99996156 0.99994564 ... 0.99995327 0.99999213 0.9999508 ]\n",
            " [0.9999755  0.99998754 0.9999677  ... 0.999978   0.9999508  1.0000153 ]]\n",
            "Similarity Matrix (Euclidean Distance):\n",
            " [[0.         0.00807354 0.00737326 ... 0.00884928 0.01024653 0.00854472]\n",
            " [0.00807354 0.         0.00708857 ... 0.00794619 0.00935293 0.00792544]\n",
            " [0.00737326 0.00708857 0.         ... 0.00744552 0.00894186 0.00768978]\n",
            " ...\n",
            " [0.00884928 0.00794619 0.00744552 ... 0.         0.00998135 0.00865518]\n",
            " [0.01024653 0.00935293 0.00894186 ... 0.00998135 0.         0.0102925 ]\n",
            " [0.00854472 0.00792544 0.00768978 ... 0.00865518 0.0102925  0.        ]]\n",
            "Similarity Matrix (Euclidean Distance2):\n",
            " [[1.         0.81874657 0.8344681  ... 0.80133104 0.76996243 0.80816853]\n",
            " [0.81874657 1.         0.8408595  ... 0.8216056  0.790024   0.82207143]\n",
            " [0.8344681  0.8408595  1.         ... 0.8328458  0.79925257 0.827362  ]\n",
            " ...\n",
            " [0.80133104 0.8216056  0.8328458  ... 1.         0.7759158  0.8056887 ]\n",
            " [0.76996243 0.790024   0.79925257 ... 0.7759158  1.         0.7689303 ]\n",
            " [0.80816853 0.82207143 0.827362   ... 0.8056887  0.7689303  1.        ]]\n",
            "Similarity Matrix (Dot Product Similarity):\n",
            " [[1.0000092  0.9999824  0.9999682  ... 0.99997365 0.9999483  0.9999755 ]\n",
            " [0.9999824  1.0000196  0.99997514 ... 0.9999855  0.99996156 0.99998754]\n",
            " [0.9999682  0.99997514 0.9999805  ... 0.9999697  0.99994564 0.9999677 ]\n",
            " ...\n",
            " [0.99997365 0.9999855  0.9999697  ... 1.0000155  0.99995327 0.999978  ]\n",
            " [0.9999483  0.99996156 0.99994564 ... 0.99995327 0.99999213 0.9999508 ]\n",
            " [0.9999755  0.99998754 0.9999677  ... 0.999978   0.9999508  1.0000153 ]]\n"
          ]
        }
      ],
      "source": [
        "# mean_attention_scores = np.mean(attention_scores, axis=1)\n",
        "mean_attention_scores = np.mean(attention_scores, axis=1)    # attention_scores or out[1]\n",
        "\n",
        "# Flatten the attention score matrices for each time series\n",
        "flattened_scores = mean_attention_scores.reshape(len(X), -1)\n",
        "normalized_scores = normalize(flattened_scores, axis=1)    # For dot product\n",
        "\n",
        "# Compute cosine similarity, euclidean distance, dot-product\n",
        "similarity_matrix_cos = cosine_similarity(flattened_scores)\n",
        "similarity_matrix_euc = euclidean_distances(flattened_scores)\n",
        "# similarity_matrix_euc = similarity_matrix_euc / np.max(similarity_matrix_euc)\n",
        "similarity_matrix_euc2 = 1 - similarity_matrix_euc / np.max(similarity_matrix_euc)\n",
        "similarity_matrix_dotp = np.dot(normalized_scores, normalized_scores.T)\n",
        "\n",
        "print(\"Similarity Matrix (Cosine Similarity):\\n\", similarity_matrix_cos)\n",
        "print(\"Similarity Matrix (Euclidean Distance):\\n\", similarity_matrix_euc)\n",
        "print(\"Similarity Matrix (Euclidean Distance2):\\n\", similarity_matrix_euc2)\n",
        "print(\"Similarity Matrix (Dot Product Similarity):\\n\", similarity_matrix_dotp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Attention Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity Matrix (Cosine Similarity):\n",
            " [[0.9999516  0.99995023 0.9999505  ... 0.9999504  0.9999501  0.999951  ]\n",
            " [0.99995023 0.99994814 0.9999489  ... 0.9999486  0.9999484  0.99994963]\n",
            " [0.9999505  0.9999489  0.9999497  ... 0.9999493  0.99994856 0.9999499 ]\n",
            " ...\n",
            " [0.9999504  0.9999486  0.9999493  ... 0.9999493  0.9999487  0.9999499 ]\n",
            " [0.9999501  0.9999484  0.99994856 ... 0.9999487  0.99994797 0.99994946]\n",
            " [0.999951   0.99994963 0.9999499  ... 0.9999499  0.99994946 0.99995035]]\n",
            "Similarity Matrix (Euclidean Distance):\n",
            " [[0.0000000e+00 3.4944989e-07 3.1912901e-07 ... 3.8303170e-07\n",
            "  4.4348832e-07 3.6983525e-07]\n",
            " [3.4944989e-07 0.0000000e+00 3.0682921e-07 ... 3.4396083e-07\n",
            "  4.0481515e-07 3.4304708e-07]\n",
            " [3.1912904e-07 3.0682921e-07 0.0000000e+00 ... 3.2229426e-07\n",
            "  3.8702808e-07 3.3284653e-07]\n",
            " ...\n",
            " [3.8303170e-07 3.4396083e-07 3.2229426e-07 ... 0.0000000e+00\n",
            "  4.3202778e-07 3.7463684e-07]\n",
            " [4.4348832e-07 4.0481515e-07 3.8702808e-07 ... 4.3202778e-07\n",
            "  0.0000000e+00 4.4547809e-07]\n",
            " [3.6983525e-07 3.4304708e-07 3.3284653e-07 ... 3.7463684e-07\n",
            "  4.4547809e-07 0.0000000e+00]]\n",
            "Similarity Matrix (Euclidean Distance2):\n",
            " [[1.         0.81874657 0.8344681  ... 0.80133104 0.76996243 0.80816853]\n",
            " [0.81874657 1.         0.8408595  ... 0.8216056  0.790024   0.82207143]\n",
            " [0.8344681  0.8408595  1.         ... 0.8328458  0.79925257 0.827362  ]\n",
            " ...\n",
            " [0.80133104 0.8216056  0.8328458  ... 1.         0.7759158  0.8056887 ]\n",
            " [0.76996243 0.790024   0.79925257 ... 0.7759158  1.         0.7689303 ]\n",
            " [0.80816853 0.82207143 0.827362   ... 0.8056887  0.7689303  1.        ]]\n",
            "Similarity Matrix (Dot Product Similarity):\n",
            " [[0.9999516  0.99995023 0.9999505  ... 0.9999504  0.9999501  0.999951  ]\n",
            " [0.99995023 0.99994814 0.9999489  ... 0.9999486  0.9999484  0.99994963]\n",
            " [0.9999505  0.9999489  0.9999497  ... 0.9999493  0.99994856 0.9999499 ]\n",
            " ...\n",
            " [0.9999504  0.9999486  0.9999493  ... 0.9999493  0.9999487  0.9999499 ]\n",
            " [0.9999501  0.9999484  0.99994856 ... 0.9999487  0.99994797 0.99994946]\n",
            " [0.999951   0.99994963 0.9999499  ... 0.9999499  0.99994946 0.99995035]]\n"
          ]
        }
      ],
      "source": [
        "# Get weights of attention scores for each time series\n",
        "attention_weights = np.exp(flattened_scores) / np.sum(np.exp(flattened_scores), axis=1, keepdims=True)\n",
        "normalized_weights = normalize(attention_weights, axis=1)\n",
        "\n",
        "# Compute cosine similarity, euclidean distance, dot-product\n",
        "similarity_matrix_cos_aw = cosine_similarity(attention_weights)\n",
        "similarity_matrix_euc_aw = euclidean_distances(attention_weights)\n",
        "# similarity_matrix_euc_aw = similarity_matrix_euc / np.max(similarity_matrix_euc)\n",
        "similarity_matrix_euc2_aw = 1 - similarity_matrix_euc / np.max(similarity_matrix_euc)\n",
        "similarity_matrix_dotp_aw = np.dot(normalized_weights, normalized_weights.T)\n",
        "\n",
        "print(\"Similarity Matrix (Cosine Similarity):\\n\", similarity_matrix_cos_aw)\n",
        "print(\"Similarity Matrix (Euclidean Distance):\\n\", similarity_matrix_euc_aw)\n",
        "print(\"Similarity Matrix (Euclidean Distance2):\\n\", similarity_matrix_euc2_aw)\n",
        "print(\"Similarity Matrix (Dot Product Similarity):\\n\", similarity_matrix_dotp_aw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Attention Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 152, 3)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_outputs.shape  # att_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity Matrix (Cosine Similarity):\n",
            " [[1.0000001  0.9979965  0.9986291  ... 0.99843097 0.9980059  0.9995406 ]\n",
            " [0.9979965  1.0000004  0.99769616 ... 0.9978208  0.99836934 0.99840117]\n",
            " [0.9986291  0.99769616 0.9999993  ... 0.99926984 0.99774843 0.99868834]\n",
            " ...\n",
            " [0.99843097 0.9978208  0.99926984 ... 1.0000004  0.9975196  0.9986215 ]\n",
            " [0.9980059  0.99836934 0.99774843 ... 0.9975196  0.9999998  0.99815845]\n",
            " [0.9995406  0.99840117 0.99868834 ... 0.9986215  0.99815845 0.99999994]]\n",
            "Similarity Matrix (Euclidean Distance):\n",
            " [[0.         0.13626182 0.11271083 ... 0.12064176 0.13613436 0.0652716 ]\n",
            " [0.13626182 0.         0.1458841  ... 0.14207463 0.12318584 0.1216918 ]\n",
            " [0.11271083 0.1458841  0.         ... 0.08227803 0.14465623 0.11021324]\n",
            " ...\n",
            " [0.12064176 0.14207463 0.08227803 ... 0.         0.15182087 0.11303952]\n",
            " [0.13613436 0.12318584 0.14465623 ... 0.15182087 0.         0.13082868]\n",
            " [0.0652716  0.1216918  0.11021324 ... 0.11303952 0.13082868 0.        ]]\n",
            "Similarity Matrix (Euclidean Distance2):\n",
            " [[1.         0.58980095 0.6606983  ... 0.6368232  0.5901847  0.80350804]\n",
            " [0.58980095 1.         0.5608343  ... 0.5723022  0.6291646  0.63366216]\n",
            " [0.6606983  0.5608343  1.         ... 0.75231236 0.5645307  0.66821694]\n",
            " ...\n",
            " [0.6368232  0.5723022  0.75231236 ... 1.         0.54296243 0.6597088 ]\n",
            " [0.5901847  0.6291646  0.5645307  ... 0.54296243 1.         0.60615677]\n",
            " [0.80350804 0.63366216 0.66821694 ... 0.6597088  0.60615677 1.        ]]\n",
            "Similarity Matrix (Dot Product Similarity):\n",
            " [[1.0000001  0.9979965  0.9986291  ... 0.99843097 0.9980059  0.9995406 ]\n",
            " [0.9979965  1.0000004  0.99769616 ... 0.9978208  0.99836934 0.99840117]\n",
            " [0.9986291  0.99769616 0.9999993  ... 0.99926984 0.99774843 0.99868834]\n",
            " ...\n",
            " [0.99843097 0.9978208  0.99926984 ... 1.0000004  0.9975196  0.9986215 ]\n",
            " [0.9980059  0.99836934 0.99774843 ... 0.9975196  0.9999998  0.99815845]\n",
            " [0.9995406  0.99840117 0.99868834 ... 0.9986215  0.99815845 0.99999994]]\n"
          ]
        }
      ],
      "source": [
        "# Reshape the attention outputs to combine batch_size and seq_len for each time series\n",
        "# mean_attention_outputs = np.mean(attention_outputs, axis=1)  # bad result\n",
        "reshaped_att_outputs = attention_outputs.reshape(len(X), -1)  # (batch_size, seq_len * embed_dim)\n",
        "normalized_outputs = normalize(reshaped_att_outputs, axis=1)\n",
        "\n",
        "# Compute cosine similarity\n",
        "similarity_matrix_cos_ao = cosine_similarity(reshaped_att_outputs)\n",
        "similarity_matrix_euc_ao = euclidean_distances(reshaped_att_outputs)\n",
        "# similarity_matrix_euc_ao = similarity_matrix_euc / np.max(similarity_matrix_euc)\n",
        "similarity_matrix_euc2_ao = 1 - similarity_matrix_euc_ao / np.max(similarity_matrix_euc_ao)\n",
        "similarity_matrix_dotp_ao = np.dot(normalized_outputs, normalized_outputs.T)\n",
        "\n",
        "print(\"Similarity Matrix (Cosine Similarity):\\n\", similarity_matrix_cos_ao)\n",
        "print(\"Similarity Matrix (Euclidean Distance):\\n\", similarity_matrix_euc_ao)\n",
        "print(\"Similarity Matrix (Euclidean Distance2):\\n\", similarity_matrix_euc2_ao)\n",
        "print(\"Similarity Matrix (Dot Product Similarity):\\n\", similarity_matrix_dotp_ao)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save(root_url + \"/att_outputs/\" + str(dataset)+\"_att_scores.npy\", similarity_matrix_euc)    # attention_scores\n",
        "np.save(root_url + \"/att_outputs/\" + str(dataset)+\"_att_weights.npy\", similarity_matrix_euc_aw)    # attention_scores\n",
        "np.save(root_url + \"/att_outputs/\" + str(dataset)+\"_att_outputs.npy\", similarity_matrix_dotp_ao)  # attention_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fHUnfgIVe1mr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30.78857922554016\n"
          ]
        }
      ],
      "source": [
        "end = time.time()\n",
        "print(end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
